{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aa7cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import cv2\n",
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "\n",
    "from camera import Camera, bgr8_to_jpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5398f0b1",
   "metadata": {},
   "source": [
    "# Collect data of checkerboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f42efac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cameraL = Camera.instance(id=0, width=820, height=616)\n",
    "cameraR = Camera.instance(id=1, width=820, height=616)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb9b986",
   "metadata": {},
   "outputs": [],
   "source": [
    "wL=widgets.Image(width=410, height=308)\n",
    "wR=widgets.Image(width=410, height=308)\n",
    "display(widgets.HBox([wL,wR]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30afabc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the images captured by the left and right cameras\n",
    "pathL = \"./data/stereoL/\"\n",
    "pathR = \"./data/stereoR/\"\n",
    "\n",
    "# Checkerboard size\n",
    "cx=8\n",
    "cy=5\n",
    "\n",
    "# Time countdown before taking image\n",
    "T = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0e0051",
   "metadata": {},
   "source": [
    "Taking pictures for calibration .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57beb67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "count = 0\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        timer = T - int(time.time() - start)\n",
    "        frameR= cameraR.value\n",
    "        frameL= cameraL.value\n",
    "\n",
    "        img1_temp = frameL.copy()\n",
    "        status=f\"{timer} - found {count}\"\n",
    "        cv2.putText(img1_temp,status,(50,75),1,4,(0,255,255),3)\n",
    "        wR.value=bgr8_to_jpeg(frameR)\n",
    "        wL.value=bgr8_to_jpeg(img1_temp)\n",
    "\n",
    "        grayR= cv2.cvtColor(frameR,cv2.COLOR_BGR2GRAY)\n",
    "        grayL= cv2.cvtColor(frameL,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chess board corners\n",
    "        retR, cornersR = cv2.findChessboardCorners(grayR,(cx,cy),None)\n",
    "        retL, cornersL = cv2.findChessboardCorners(grayL,(cx,cy),None)\n",
    "\n",
    "        # If corners are detected in left and right image then we save it.\n",
    "        if (retR == True) and (retL == True) and timer <=0:\n",
    "            count+=1\n",
    "            cv2.imwrite(pathR+'img%d.png'%count,frameR)\n",
    "            cv2.imwrite(pathL+'img%d.png'%count,frameL)\n",
    "\n",
    "        if timer <=0:\n",
    "            start = time.time()\n",
    "except KeyboardInterrupt:\n",
    "    print('Done ..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88945cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cameraL.stop()\n",
    "cameraR.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4f9161",
   "metadata": {},
   "source": [
    "# Calibration using images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2956aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting image coordinates of respective 3D pattern ....\\n\")\n",
    "\n",
    "# Termination criteria for refining the detected corners\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "objp = np.zeros((cx*cy,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:cx,0:cy].T.reshape(-1,2)\n",
    "\n",
    "img_ptsL = []\n",
    "img_ptsR = []\n",
    "obj_pts = []\n",
    "\n",
    "nfiles = len(glob.glob(pathL+\"img*.png\"))\n",
    "for i in range(1,nfiles+1):\n",
    "    print(f\"Reading img{i}.png ..\")\n",
    "    imgL = cv2.imread(pathL+\"img%d.png\"%i)\n",
    "    imgR = cv2.imread(pathR+\"img%d.png\"%i)\n",
    "    imgL_gray = cv2.imread(pathL+\"img%d.png\"%i,0)\n",
    "    imgR_gray = cv2.imread(pathR+\"img%d.png\"%i,0)\n",
    "\n",
    "    outputL = imgL.copy()\n",
    "    outputR = imgR.copy()\n",
    "\n",
    "    retR, cornersR =  cv2.findChessboardCorners(outputR,(cx,cy),None)\n",
    "    retL, cornersL = cv2.findChessboardCorners(outputL,(cx,cy),None)\n",
    "\n",
    "    if retR and retL:\n",
    "        obj_pts.append(objp)\n",
    "        cv2.cornerSubPix(imgR_gray,cornersR,(11,11),(-1,-1),criteria)\n",
    "        cv2.cornerSubPix(imgL_gray,cornersL,(11,11),(-1,-1),criteria)\n",
    "        cv2.drawChessboardCorners(outputR,(cx,cy),cornersR,retR)\n",
    "        cv2.drawChessboardCorners(outputL,(cx,cy),cornersL,retL)\n",
    "        cv2.imwrite(pathL+'/calib%d.png'%i,outputL)\n",
    "        cv2.imwrite(pathR+'/calib%d.png'%i,outputR)\n",
    "\n",
    "        img_ptsL.append(cornersL)\n",
    "        img_ptsR.append(cornersR)\n",
    "\n",
    "\n",
    "print(\"Calculating left camera parameters ... \")\n",
    "# Calibrating left camera\n",
    "retL, mtxL, distL, rvecsL, tvecsL = cv2.calibrateCamera(obj_pts,img_ptsL,imgL_gray.shape[::-1],None,None)\n",
    "hL,wL= imgL_gray.shape[:2]\n",
    "new_mtxL, roiL= cv2.getOptimalNewCameraMatrix(mtxL,distL,(wL,hL),1,(wL,hL))\n",
    "\n",
    "print(\"Calculating right camera parameters ... \")\n",
    "# Calibrating right camera\n",
    "retR, mtxR, distR, rvecsR, tvecsR = cv2.calibrateCamera(obj_pts,img_ptsR,imgR_gray.shape[::-1],None,None)\n",
    "hR,wR= imgR_gray.shape[:2]\n",
    "new_mtxR, roiR= cv2.getOptimalNewCameraMatrix(mtxR,distR,(wR,hR),1,(wR,hR))\n",
    "\n",
    "\n",
    "print(\"Stereo calibration .....\")\n",
    "flags = 0\n",
    "flags |= cv2.CALIB_FIX_INTRINSIC\n",
    "# Here we fix the intrinsic camara matrixes so that only Rot, Trns, Emat and Fmat are calculated.\n",
    "# Hence intrinsic parameters are the same \n",
    "\n",
    "criteria_stereo= (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "\n",
    "# This step is performed to transformation between the two cameras and calculate Essential and Fundamenatl matrix\n",
    "retS, new_mtxL, distL, new_mtxR, distR, Rot, Trns, Emat, Fmat = cv2.stereoCalibrate(obj_pts,\n",
    "                                                          img_ptsL,\n",
    "                                                          img_ptsR,\n",
    "                                                          new_mtxL,\n",
    "                                                          distL,\n",
    "                                                          new_mtxR,\n",
    "                                                          distR,\n",
    "                                                          imgL_gray.shape[::-1],\n",
    "                                                          criteria_stereo,\n",
    "                                                          flags)\n",
    "\n",
    "# Once we know the transformation between the two cameras we can perform stereo rectification\n",
    "# StereoRectify function\n",
    "rectify_scale= 1 # if 0 image croped, if 1 image not croped\n",
    "rect_l, rect_r, proj_mat_l, proj_mat_r, Q, roiL, roiR= cv2.stereoRectify(new_mtxL, distL, new_mtxR, distR,\n",
    "                                                 imgL_gray.shape[::-1], Rot, Trns,\n",
    "                                                 rectify_scale,(0,0))\n",
    "\n",
    "# Use the rotation matrixes for stereo rectification and camera intrinsics for undistorting the image\n",
    "# Compute the rectification map (mapping between the original image pixels and \n",
    "# their transformed values after applying rectification and undistortion) for left and right camera frames\n",
    "Left_Stereo_Map= cv2.initUndistortRectifyMap(new_mtxL, distL, rect_l, proj_mat_l,\n",
    "                                             imgL_gray.shape[::-1], cv2.CV_16SC2)\n",
    "Right_Stereo_Map= cv2.initUndistortRectifyMap(new_mtxR, distR, rect_r, proj_mat_r,\n",
    "                                              imgR_gray.shape[::-1], cv2.CV_16SC2)\n",
    "\n",
    "\n",
    "print(\"Saving parameters ......\")\n",
    "cv_file = cv2.FileStorage(\"data/params_py.xml\", cv2.FILE_STORAGE_WRITE)\n",
    "cv_file.write(\"Left_Stereo_Map_x\",Left_Stereo_Map[0])\n",
    "cv_file.write(\"Left_Stereo_Map_y\",Left_Stereo_Map[1])\n",
    "cv_file.write(\"Right_Stereo_Map_x\",Right_Stereo_Map[0])\n",
    "cv_file.write(\"Right_Stereo_Map_y\",Right_Stereo_Map[1])\n",
    "cv_file.release()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce1d92b",
   "metadata": {},
   "source": [
    "Plotting the calibration images .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96870e67",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nfiles = len(glob.glob(pathL+\"calib*.png\"))\n",
    "imageWidgets = []\n",
    "\n",
    "for i in range(1,nfiles+1):\n",
    "    calL = cv2.imread(pathL+\"calib%d.png\"%i)\n",
    "    calR = cv2.imread(pathR+\"calib%d.png\"%i)\n",
    "    imageWidgets.append(widgets.HBox([widgets.Image(value=bgr8_to_jpeg(calL), width=410, height=308), \n",
    "                                      widgets.Image(value=bgr8_to_jpeg(calR), width=410, height=308)]))\n",
    "    \n",
    "display(widgets.VBox(imageWidgets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52921347",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
